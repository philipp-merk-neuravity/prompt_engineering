{
  "version": "0.2.0",
  "configurations": [
    {
      "name": "Run CodeT",
      "type": "python",
      "request": "launch",
      "program": "/home/neuravity/dev/prompt_engineering/CodeT/src/main.py",
      "args": [
          "--source_path_for_solution", "/home/neuravity/dev/prompt_engineering/CodeT/src/data/dataset/HumanEval_for_code_generation.jsonl",
          "--predict_path_for_solution", "/home/neuravity/dev/prompt_engineering/CodeT/src/data/generated_data/HumanEval_davinci002_temp0.8_topp0.95_num100_max300_code_solution.jsonl",
          "--source_path_for_test", "/home/neuravity/dev/prompt_engineering/CodeT/src/data/dataset/HumanEval_for_test_case_generation.jsonl",
          "--predict_path_for_test", "/home/neuravity/dev/prompt_engineering/CodeT/src/data/generated_data/HumanEval_davinci002_temp0.8_topp0.95_num100_max300_test_case.jsonl",
          "--timeout", "0.1",
          "--test_case_limit", "5"
      ],
      "console": "integratedTerminal"
    },
    {
      "name": "Python Debugger: Current File",
      "type": "debugpy",
      "request": "launch",
      "program": "${file}",
      "console": "integratedTerminal",
      "cwd": "${workspaceFolder}"
    },
    {
      "name": "Evaluate Code Solutions",
      "type": "python",
      "request": "launch",
      "program": "${workspaceFolder}/src/human_eval/human_eval/evaluate_functional_correctness.py",
      "console": "integratedTerminal",
      "args": [
        "--sample_file", "/home/neuravity/dev/prompt_engineering/src/benchmark_results/all/reflection/8_reflexion_without_few_shot_reflexion_without_few_shot_gpt-3.5-turbo-0125_gpt-3.5-turbo-0125/8_reflexion_without_few_shot_reflexion_without_few_shot_gpt-3.5-turbo-0125_gpt-3.5-turbo-0125.jsonl",
        "--problem_file", "/home/neuravity/dev/prompt_engineering/src/human_eval/data/HumanEval.jsonl",
      ],
    },
    {
      "name": "Debug gen_tests.py with Args",
      "type": "python",
      "request": "launch",
      "program": "${workspaceFolder}/src/gen_tests.py",
      "console": "integratedTerminal",
      "args": [
        "--model", "gpt-3.5-turbo-0125",
        "--prompt_type", "few_shot",
        "--chunk_size", "1",
        "--model_for_refinement", "gpt-3.5-turbo-0125",
      ],
      "cwd": "${workspaceFolder}/src"
    },
    {
      "name": "Debug eval_tests.py with Args",
      "type": "python",
      "request": "launch",
      "program": "${workspaceFolder}/src/eval_tests.py",
      "console": "integratedTerminal",
      "args": [
        "--path_for_test_cases", "/home/neuravity/dev/prompt_engineering/src/benchmark_results/test_cases/io/gpt-3.5-turbo-0125/3/3.jsonl",
      ],
      "cwd": "${workspaceFolder}/src"
    },
    {
      "name": "Debug simple.py with Args",
      "type": "python",
      "request": "launch",
      "program": "${workspaceFolder}/src/simple.py",
      "console": "integratedTerminal",
      "args": [
        "--model", "gpt-3.5-turbo-0125",
        "--prompt_type", "io",
        "--benchmark_type", "all",
        "--chunk_size", "166",
        "--delay_seconds", "20",
        "--temperature", "0.2"
      ],
      "cwd": "${workspaceFolder}/src"
    },
    {
      "name": "Reflection (Tests: gpt-4, Init: gpt-4)",
      "type": "python",
      "request": "launch",
      "program": "${workspaceFolder}/src/reflection.py",
      "console": "integratedTerminal",
      "args": [
        "--model_for_reflection", "gpt-4-0125-preview",
        "--model_for_refinement", "gpt-4-0125-preview",
        "--prompt_for_reflection", "reflexion_without_few_shot",
        "--prompt_for_refinement", "reflexion_without_few_shot",
        "--max_iterations", "3",
        "--benchmark_type", "all",
        "--chunk_size", "50",
        "--tests_path", "/home/neuravity/dev/prompt_engineering/src/benchmark_results/test_cases/few_shot/gpt-3.5-turbo-0125/with_refinement/gpt-3.5-turbo-0125/combined_results.jsonl",
        "--file_path_for_init", "/home/neuravity/dev/prompt_engineering/src/benchmark_results/all/simple/io/gpt-4-0125-preview/1/1.jsonl",
        "--test_case_type", "gpt3.5_gpt3.5_gpt3.5"
      ],
      "cwd": "${workspaceFolder}/src"
    },
    {
      "name": "Reflection (Tests: gpt-3, Init: gpt-3.5-turbo-0125)",
      "type": "python",
      "request": "launch",
      "program": "${workspaceFolder}/src/reflection.py",
      "console": "integratedTerminal",
      "args": [
        "--model_for_reflection", "gpt-3.5-turbo-0125",
        "--model_for_refinement", "gpt-3.5-turbo-0125",
        "--prompt_for_reflection", "reflexion_without_few_shot",
        "--prompt_for_refinement", "reflexion_without_few_shot",
        "--max_iterations", "4",
        "--benchmark_type", "all",
        "--chunk_size", "50",
        "--tests_path", "/home/neuravity/dev/prompt_engineering/src/benchmark_results/test_cases/few_shot/gpt-4-0125-preview/with_refinement/gpt-4-0125-preview/combined_results.jsonl",
        "--file_path_for_init", "/home/neuravity/dev/prompt_engineering/src/benchmark_results/all/simple/io/gpt-3.5-turbo-0125/4/4.jsonl",
        "--test_case_type", "gpt3.5_gpt4_gpt4"
      ],
      "cwd": "${workspaceFolder}/src"
    },
  ],
}