{
  "version": "0.2.0",
  "configurations": [
    {
      "name": "Python Debugger: Current File",
      "type": "debugpy",
      "request": "launch",
      "program": "${file}",
      "console": "integratedTerminal",
      "cwd": "${workspaceFolder}"
    },
    {
      "name": "Evaluate Code Solutions",
      "type": "python",
      "request": "launch",
      "program": "${workspaceFolder}/src/human_eval/human_eval/evaluate_functional_correctness.py",
      "console": "integratedTerminal",
      "args": [
        "--sample_file", "/home/neuravity/dev/prompt_engineering/src/benchmark_results/all/reflection/8_reflexion_without_few_shot_reflexion_without_few_shot_gpt-3.5-turbo-0125_gpt-3.5-turbo-0125/8_reflexion_without_few_shot_reflexion_without_few_shot_gpt-3.5-turbo-0125_gpt-3.5-turbo-0125.jsonl",
        "--problem_file", "/home/neuravity/dev/prompt_engineering/src/human_eval/data/HumanEval.jsonl",
      ],
    },
    {
      "name": "Debug gen_tests.py with Args",
      "type": "python",
      "request": "launch",
      "program": "${workspaceFolder}/src/gen_tests.py",
      "console": "integratedTerminal",
      "args": [
        "--model", "gpt-3.5-turbo-0125",
        "--prompt_type", "few_shot",
        "--chunk_size", "50"
      ],
      "cwd": "${workspaceFolder}/src"
    },
    {
      "name": "Debug eval_tests.py with Args",
      "type": "python",
      "request": "launch",
      "program": "${workspaceFolder}/src/eval_tests.py",
      "console": "integratedTerminal",
      "args": [
        "--path_for_test_cases", "/home/neuravity/dev/prompt_engineering/src/benchmark_results/test_cases/few_shot/gpt-3.5-turbo-0125/1/1.jsonl",
      ],
      "cwd": "${workspaceFolder}/src"
    },
    {
      "name": "Debug simple.py with Args",
      "type": "python",
      "request": "launch",
      "program": "${workspaceFolder}/src/simple.py",
      "console": "integratedTerminal",
      "args": [
        "--model", "gpt-4-0125-preview",
        "--prompt_type", "agentCoder",
        "--benchmark_type", "all",
        "--chunk_size", "57",
        "--delay_seconds", "10"
      ],
      "cwd": "${workspaceFolder}/src"
    },
    {
      "name": "Reflection (Tests: gpt-3.5-turbo-0125, Init: gpt-4)",
      "type": "python",
      "request": "launch",
      "program": "${workspaceFolder}/src/reflection.py",
      "console": "integratedTerminal",
      "args": [
        "--model_for_reflection", "gpt-4-0125-preview",
        "--model_for_refinement", "gpt-4-0125-preview",
        "--prompt_for_reflection", "reflexion_without_few_shot",
        "--prompt_for_refinement", "reflexion_without_few_shot",
        "--max_iterations", "4",
        "--benchmark_type", "all",
        "--chunk_size", "50",
        "--tests_path", "/home/neuravity/dev/prompt_engineering/src/benchmark_results/test_cases/io/gpt-3.5-turbo-0125/2/2.jsonl",
        "--file_path_for_init", "/home/neuravity/dev/prompt_engineering/src/benchmark_results/all/simple/io/gpt-4-0125-preview/0/0.jsonl",
        "--test_case_type", "with_gpt-3.5-turbo_test_cases"
      ],
      "cwd": "${workspaceFolder}/src"
    },
    {
      "name": "Reflection (Tests: gpt-3, Init: gpt-3.5-turbo-0125)",
      "type": "python",
      "request": "launch",
      "program": "${workspaceFolder}/src/reflection.py",
      "console": "integratedTerminal",
      "args": [
        "--model_for_reflection", "gpt-3.5-turbo-0125",
        "--model_for_refinement", "gpt-3.5-turbo-0125",
        "--prompt_for_reflection", "reflexion_without_few_shot",
        "--prompt_for_refinement", "reflexion_without_few_shot",
        "--max_iterations", "4",
        "--benchmark_type", "all",
        "--chunk_size", "50",
        "--tests_path", "/home/neuravity/dev/prompt_engineering/src/benchmark_results/test_cases/few_shot/gpt-3.5-turbo-0125/0/0.jsonl",
        "--file_path_for_init", "/home/neuravity/dev/prompt_engineering/src/benchmark_results/all/simple/io/gpt-3.5-turbo-0125/4/4.jsonl",
        "--test_case_type", "with_gpt-3.5-turbo_test_cases_4"
      ],
      "cwd": "${workspaceFolder}/src"
    },
    {
      "name": "Reflection (Tests: predefined, Init: gpt-3.5-turbo-0125)",
      "type": "python",
      "request": "launch",
      "program": "${workspaceFolder}/src/reflection.py",
      "console": "integratedTerminal",
      "args": [
        "--model_for_reflection", "gpt-3.5-turbo-0125",
        "--model_for_refinement", "gpt-3.5-turbo-0125",
        "--prompt_for_reflection", "reflexion_without_few_shot",
        "--prompt_for_refinement", "reflexion_without_few_shot",
        "--max_iterations", "4",
        "--benchmark_type", "all",
        "--chunk_size", "50",
        "--tests_path", "/home/neuravity/dev/prompt_engineering/src/human_eval/data/ExtractedTests.json",
        "--file_path_for_init", "/home/neuravity/dev/prompt_engineering/src/benchmark_results/all/simple/io/gpt-3.5-turbo-0125/4/4.jsonl",
        "--test_case_type", "with_predefined_test_cases"
      ],
      "cwd": "${workspaceFolder}/src"
    },
  ]
}